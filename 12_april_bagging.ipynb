{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8e051bce-6505-4904-80c8-88d778d67c11",
   "metadata": {},
   "source": [
    "Q1. How does bagging reduce overfitting in decision trees?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0adc988d-b4bc-4d39-b043-3619eb4b7da4",
   "metadata": {},
   "source": [
    "Solution :"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6173c07b-d144-41f6-9f05-09246657b8db",
   "metadata": {},
   "source": [
    "Bagging is an ensemble method which combines multiple models to improve the overall accuracy of the machine learning algorithm. Bagging is a technique used with decision trees to improve accuracy and reduce variane , whivh eliminates the challange of overfitting.\n",
    "\n",
    "Bagging reduces overfitting by averaging or voting ,however this leads to increase in bias , which is compensated by the reduction in variance through. By combining multiple models, bagging helps to reduce the model's variance and can prevent overfitting by introducing diversity into the training process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8035701-85c5-487f-9c56-a1093b6c1b01",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f53246c-7f84-480f-890b-bf412d21fa28",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "79cc740a-cf45-4178-8735-063bd0bee8ca",
   "metadata": {},
   "source": [
    "Q2. What are the advantages and disadvantages of using different types of base learners in bagging?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "273da26f-66db-4e8e-8398-cd8c9993802b",
   "metadata": {},
   "source": [
    "Solution :"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f5795c4-e533-4899-b892-b0f474a8641f",
   "metadata": {},
   "source": [
    "Bagging works especially well when the learners are unstable and tend to overfit, i.e. small changes in the training data lead to major changes in the predicted output. It effectively reduces the variance by aggregating the individual learners composed of different statistical properties, such as different standard deviations, means, etc. The biggest advantage of bagging is that multiple weak learners can work better than a single strong learner. It provides stability and increases the machine learning algorithm’s accuracy that is used in statistical classification and regression. It helps in reducing variance, i.e. it avoids overfitting.\n",
    "\n",
    "One disadvantage of bagging is that it introduces a loss of interpretability of a model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a6a95a4-6d2b-4ff8-938f-e208cd25e94b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dc453bc-fa60-4129-a778-099c92665b40",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "22c0bf03-0443-44fe-87c6-edcf50cd9e0f",
   "metadata": {},
   "source": [
    "Q3. How does the choice of base learner affect the bias-variance tradeoff in bagging?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e96be68-22eb-477f-9d76-dc467e7cbf3e",
   "metadata": {},
   "source": [
    "Solution :"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd4da3dc-8fab-4ac5-8bf3-eb39e3858081",
   "metadata": {},
   "source": [
    "The choice of base learner affects the bias-variance tradeoff in bagging. Lowering a model’s bias leads to an increase in its variance and vice versa. The k-nearest neighbors algorithm has low bias and high variance, but the trade-off can be changed by increasing the value of k which increases the number of neighbors that contribute to the prediction and in turn increases the bias of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0db083c9-75bc-4376-83c8-3eeb18379c4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdce9f76-f9c0-45a4-a000-59c3168c7205",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "45d8f0c0-7851-44c8-b6d7-8fbb93c8e90e",
   "metadata": {},
   "source": [
    "Q4. Can bagging be used for both classification and regression tasks? How does it differ in each case?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f925b932-f77e-45a1-9195-bec0160153eb",
   "metadata": {},
   "source": [
    "Solution :"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1373c8aa-9b40-4cd4-903e-0e2eda2aa25e",
   "metadata": {},
   "source": [
    "Yes, bagging can be used for both classification and regression problems.The main difference between these two kind of problems is that in classification problem , we do voting . The prediction comes max times that will be the final prediction. In regression problem , we do the average of all predictions to get the final prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22b5cdc0-ccf1-4070-8447-80542912e541",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b104f3b3-d363-44be-9b10-769bddcd3a04",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cee6116e-f54c-47d5-8e8c-bfb82a439917",
   "metadata": {},
   "source": [
    "Q5. What is the role of ensemble size in bagging? How many models should be included in the ensemble?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2167114e-2a62-40ad-a7e5-99e07a03166c",
   "metadata": {},
   "source": [
    "Solution :"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b279297e-653d-4606-8fa1-e7418198774f",
   "metadata": {},
   "source": [
    "The ensemble size in bagging is an important parameter that affects the performance of the model. The optimal number of models to include in the ensemble depends on the dataset and the complexity of the problem. In general, increasing the number of models in the ensemble improves the performance of the model up to a certain point, beyond which it starts to decrease."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d413d355-1800-4e4f-9641-2deaddd50570",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c930974-5a69-4e09-8c8c-ec0047afd8a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6c8cd925-7c49-416e-9a12-555444344e5b",
   "metadata": {},
   "source": [
    "Q6. Can you provide an example of a real-world application of bagging in machine learning?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e459ee84-924a-4852-bfcf-10713276775f",
   "metadata": {},
   "source": [
    "Solution :"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c628c0c2-36ca-4e26-85f9-ee77f45898cf",
   "metadata": {},
   "source": [
    "Bagging is used in many real-world applications of machine learning. One example is in the field of finance, where it is used to predict stock prices. Another example is in the field of medical diagnosis, where it is used to predict the likelihood of a patient having a certain disease."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1031911-92b1-47cd-835e-cc4dcc242ebd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
