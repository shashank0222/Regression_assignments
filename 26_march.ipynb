{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a1b55f10-7e4d-4f0d-8e50-0dbfcfe49eef",
   "metadata": {},
   "source": [
    "Q1. Explain the difference between simple linear regression and multiple linear regression. Provide an\n",
    "example of each."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf2fbded-9c4c-4d3f-8e51-6023eeac6538",
   "metadata": {},
   "source": [
    "Solution :"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9fcb239-c3d4-46d5-bfd6-b0e8e2a4fbee",
   "metadata": {},
   "source": [
    "Simple linear regression is when you have only one predictor, or X variable, predicting the response or Y variable. Simple linear regression occurs in 2 dimension. For instance, when we predict rent based on square feet alone that is simple linear regression.\n",
    "\n",
    "Multiple linear regression has one y and two or more x variables. For instance, when we predict rent based on square feet and age of the building that is an example of multiple linear regression. Multiple linear regression is a more specific calculation than simple linear regression. For straight-forward relationships, simple linear regression may easily capture the relationship between the two variables. For more complex relationships requiring more consideration, multiple linear regression is often better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "134ecfb7-9326-4755-88e8-b286ac0e74dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9157f861-ec9b-4c4b-a83a-f091eb930978",
   "metadata": {},
   "source": [
    "Q2. Discuss the assumptions of linear regression. How can you check whether these assumptions hold in\n",
    "a given dataset?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a631698-e837-40e6-872c-571056ae9ea6",
   "metadata": {},
   "source": [
    "Solution :"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "900b76a1-52c2-4b88-9834-3ba0217b8400",
   "metadata": {},
   "source": [
    "The assumptions of linear regression are:\n",
    "\n",
    "1. Linearity: There should be a linear relationship between the independent variable(s) and the dependent variable.\n",
    "2. Independence: The residuals (the difference between the observed value and the predicted value) should be independent of each other.\n",
    "3. Homoscedasticity: The variance of the residuals should be constant across all levels of the independent variable(s).\n",
    "4. Normality: The residuals should be normally distributed.\n",
    "\n",
    "These assumptions can be validated by various methods, such as scatter plots, residual plots, and hypothesis tests.\n",
    "\n",
    "To check whether these assumptions hold in a given dataset, you can use residual plots to check for linearity and homoscedasticity. You can also use Q-Q plots to check for normality. Additionally, you can use statistical tests like Shapiro-Wilk to test for normality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a35e8d95-9073-42a8-bc55-7b6d67c5c65c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "006397d6-dac0-418a-873e-44a3a8e40783",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4c7e9860-34b0-42fc-988a-7c173da76f29",
   "metadata": {},
   "source": [
    "Q3. How do you interpret the slope and intercept in a linear regression model? Provide an example using\n",
    "a real-world scenario."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c5f924c-9d40-4550-aee1-7bea1e1b66c3",
   "metadata": {},
   "source": [
    "Solution :"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3427b47-cdf1-483a-bc3d-c97816880743",
   "metadata": {},
   "source": [
    "In a linear regression model, the slope represents the change in the dependent variable for every one-unit change in the independent variable. The slope is positive if the relationship between the two variables is positive and negative if the relationship is negative.\n",
    "\n",
    "The intercept represents the value of the dependent variable when the independent variable is zero. It is important to note that the intercept may not always have a meaningful interpretation.\n",
    "\n",
    "For example, suppose we want to predict how much time it will take to complete a project based on the number of people working on it. If we fit a linear regression model to this data, we might find that the slope is 2.5 and the intercept is 10. This means that for every additional person working on the project, we expect it to take an additional 2.5 units of time to complete. Additionally, if there are no people working on the project, we expect it to take 10 units of time to complete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7702f269-b9de-42e2-8c38-92838605958a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68efcdd2-751e-4e36-832a-baeaf761655d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8c49d706-a485-4e89-a79b-35a6a2152b61",
   "metadata": {},
   "source": [
    "Q4. Explain the concept of gradient descent. How is it used in machine learning?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71c2adba-e788-4149-9f95-c2cf75fc55f8",
   "metadata": {},
   "source": [
    "Solution :"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "352516ab-527d-4b5c-a44f-3efb034d726d",
   "metadata": {},
   "source": [
    "Gradient descent is an optimization algorithm used to minimize the cost function in machine learning. The cost function is a measure of how well the model fits the data. Gradient descent works by iteratively adjusting the parameters of the model in the direction of steepest descent of the cost function.\n",
    "\n",
    "The basic idea behind gradient descent is to start with an initial guess for the parameters of the model and then iteratively adjust them until the cost function is minimized. At each iteration, the algorithm calculates the gradient of the cost function with respect to each parameter and then updates the parameters in the direction of steepest descent.\n",
    "\n",
    "Gradient descent is used in many machine learning algorithms, including linear regression, logistic regression, and neural networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a71ad3b-8daa-44af-bf15-b05c3a74aba8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7df5f98-1cf2-46b1-8827-38730aae1867",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "73cfdaba-23a2-476e-be54-24c4ef263014",
   "metadata": {},
   "source": [
    "Q5. Describe the multiple linear regression model. How does it differ from simple linear regression?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f755563-d135-4679-a763-dc5bea0c4708",
   "metadata": {},
   "source": [
    "Solution :"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc64d4eb-51df-4de8-9939-e1861b8361bb",
   "metadata": {},
   "source": [
    "Multiple linear regression is a statistical method used to model the relationship between two or more independent variables and a dependent variable. It is an extension of simple linear regression, which models the relationship between one independent variable and a dependent variable.\n",
    "\n",
    "In multiple linear regression, the model takes the form:\n",
    "\n",
    "y = b0 + b1x1 + b2x2 + … + bnxn + e\n",
    "\n",
    "where y is the dependent variable, x1, x2, …, xn are the independent variables, b0 is the intercept, bn is the coefficient for the nth independent variable, and e is the error term.\n",
    "\n",
    "The goal of multiple linear regression is to find the values of b0, b1, b2, …, bn that minimize the sum of squared errors between the predicted values of y and the actual values of y.\n",
    "\n",
    "Multiple linear regression differs from simple linear regression in that it models the relationship between two or more independent variables and a dependent variable instead of just one independent variable and a dependent variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86223188-1626-4413-bb19-2d62efa20120",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ed4ad68-90f8-40fd-b3f5-92c71cf0e072",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "44ef30d1-77ff-4fed-a5ce-ff0ef84a252c",
   "metadata": {},
   "source": [
    "Q6. Explain the concept of multicollinearity in multiple linear regression. How can you detect and\n",
    "address this issue?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "842f9c66-b1ba-4d31-8eaa-78a2be20619b",
   "metadata": {},
   "source": [
    "Solution :"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8086801d-ef51-4d71-b1f1-65cf934aaef4",
   "metadata": {},
   "source": [
    "Multicollinearity is a phenomenon that occurs when two or more independent variables in a multiple linear regression model are highly correlated with each other. This can cause problems in the model because it makes it difficult to determine the effect of each independent variable on the dependent variable.\n",
    "\n",
    "One way to detect multicollinearity is to calculate the correlation matrix between the independent variables. If two or more independent variables have a high correlation coefficient (e.g., greater than 0.8), then there may be multicollinearity in the model.\n",
    "\n",
    "There are several ways to address multicollinearity in a multiple linear regression model. One approach is to remove one or more of the highly correlated independent variables from the model. Another approach is to combine the highly correlated independent variables into a single variable using principal component analysis (PCA) or factor analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c634348-3c27-4230-907f-5c312ec7cb43",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32798ede-122f-4d98-b0f8-bb05351fdc53",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "37041775-d633-44f6-abb2-a7973ef98d39",
   "metadata": {},
   "source": [
    "Q7. Describe the polynomial regression model. How is it different from linear regression?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeea2619-99ff-4a96-94ff-a20c80be737f",
   "metadata": {},
   "source": [
    "Solution :"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b07b474e-14a4-40d3-998b-58d209248a68",
   "metadata": {},
   "source": [
    "Polynomial regression is a statistical method used to model the relationship between a dependent variable and one or more independent variables using a polynomial function. It is an extension of linear regression, which models the relationship between a dependent variable and one independent variable using a linear function.\n",
    "\n",
    "In polynomial regression, the model takes the form:\n",
    "\n",
    "y = b0 + b1x + b2x^2 + … + bnx^n + e\n",
    "\n",
    "where y is the dependent variable, x is the independent variable, n is the degree of the polynomial, bn is the coefficient for the nth term of the polynomial, and e is the error term.\n",
    "\n",
    "The goal of polynomial regression is to find the values of b0, b1, b2, …, bn that minimize the sum of squared errors between the predicted values of y and the actual values of y.\n",
    "\n",
    "Polynomial regression differs from linear regression in that it models the relationship between a dependent variable and one or more independent variables using a polynomial function instead of a linear function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08f943cb-d34c-4a95-9ac6-4ab675674df4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96015a77-7909-4983-8136-b264c9e1bfbd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6e23c7cc-73c2-4e3e-a346-3988980fa89d",
   "metadata": {},
   "source": [
    "Q8. What are the advantages and disadvantages of polynomial regression compared to linear\n",
    "regression? In what situations would you prefer to use polynomial regression?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ed6264e-80a9-4688-aa52-fa3db2da8396",
   "metadata": {},
   "source": [
    "Solution :"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99234781-e970-46b1-a25c-fd6b1662707b",
   "metadata": {},
   "source": [
    "The advantages of polynomial regression over linear regression are that it can model more complex relationships between the dependent variable and the independent variable(s) and can provide a better fit to the data. The disadvantages of polynomial regression are that it can be more difficult to interpret than linear regression and can be more prone to overfitting.\n",
    "\n",
    "Polynomial regression is useful when the relationship between the dependent variable and the independent variable(s) is nonlinear. It is also useful when there are interactions between the independent variables.\n",
    "\n",
    "Linear regression is useful when the relationship between the dependent variable and the independent variable(s) is linear. It is also useful when there are no interactions between the independent variables.\n",
    "\n",
    "In general, polynomial regression should be used when there is evidence that the relationship between the dependent variable and the independent variable(s) is nonlinear. Linear regression should be used when there is evidence that the relationship between the dependent variable and the independent variable(s) is linear."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0d753fb-1486-46a3-a229-e275aa031802",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
