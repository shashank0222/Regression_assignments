{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "61554e8c-6d1a-4e6c-926b-0e613187917c",
   "metadata": {},
   "source": [
    "Q1. What is Lasso Regression, and how does it differ from other regression techniques?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b56f71e7-d954-49ac-bfce-f215ec951d24",
   "metadata": {},
   "source": [
    "Solution :"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00d8f7b1-a5fc-4023-a453-08a8ad2732c5",
   "metadata": {},
   "source": [
    "Lasso regression is a type of linear regression that is used to reduce the complexity of the model and prevent overfitting. Lasso regression, also known as L1 regularization, shrinks the coefficients to zero by taking the magnitude of the coefficients.Lasso regularization is more appropriate when we have a large number of features and we want to select only a few important features. It is also useful when we want to avoid overfitting by reducing the number of features in our model.\n",
    "\n",
    "Lasso Regression is different from ridge regression as Ridge regression shrinks the coefficients to small values by taking the square of the coefficients.Ridge regularization is more appropriate when we have multicollinearity in our data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85834670-c79d-48cd-b554-5492ef4001d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8bdb9de-0114-4701-951f-8c594be5e5b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3510d408-2672-4584-aaa7-6b8bb344a37b",
   "metadata": {},
   "source": [
    "Q2. What is the main advantage of using Lasso Regression in feature selection?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "634e130b-e8be-4b9b-8f1f-52175c5207c0",
   "metadata": {},
   "source": [
    "Solution :"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e99f37bf-fdff-483e-984f-10c61919b35d",
   "metadata": {},
   "source": [
    "The main advantage of Lasso Regression in feature selection is that it has the ability to set the coefficients for features it does not consider interesting to zero. This means that the model does some automatic feature selection to decide which features should and should not be included on its own. Reduced overfitting is another advantage of Lasso Regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b6c30be-bb41-4c1d-b789-e6bc538069fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13b6bc9d-a912-456e-b9ab-473324e78555",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "380efe2a-4903-4d36-a6dc-cf0475601a73",
   "metadata": {},
   "source": [
    "Q3. How do you interpret the coefficients of a Lasso Regression model?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cba9a640-605c-49bb-ab01-f5b9bbd21f03",
   "metadata": {},
   "source": [
    "Solution :"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00c9892d-9b80-4ea9-8f37-8260294d0c4b",
   "metadata": {},
   "source": [
    "The coefficients of a Lasso Regression model can be interpreted in the same way as logistic regression. The exponentiated coefficients from the Lasso regression yield the log odds for a 1 unit change in the coefficient while holding all other coefficients constant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "375702fc-2854-4801-b9bc-0b90c9f1cd91",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab28c61f-4a0d-43f7-90bf-76de623a07d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ec5a6ed2-22b2-44d2-b20a-30e99830ddb8",
   "metadata": {},
   "source": [
    "Q4. What are the tuning parameters that can be adjusted in Lasso Regression, and how do they affect the\n",
    "model's performance?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf4e68eb-8faa-4576-8b47-cbbaae3d92c7",
   "metadata": {},
   "source": [
    "Solution :"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79ad7361-1d8d-4e3d-ba0e-d05d501f618f",
   "metadata": {},
   "source": [
    "The tuning parameter in Lasso Regression is the regularization parameter λ. The choice of the regularization parameter λ is crucial in Lasso Regression. A larger λ value increases the amount of regularization, leading to more coefficients being pushed towards zero. Conversely, a smaller λ value reduces the regularization effect, allowing more variables to have non-zero coefficients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21c785b8-027b-4eaa-89ae-291e2d09f2c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7cc9267-9c16-4034-919d-5010bd12e9f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9331ff70-845a-4af1-b4c5-476599bb7df4",
   "metadata": {},
   "source": [
    "Q5. Can Lasso Regression be used for non-linear regression problems? If yes, how?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9093ef02-800f-4d1a-bdf8-6282e920a04e",
   "metadata": {},
   "source": [
    "Solution :"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2273472-d0ea-4b10-b157-8b8228ba5fc8",
   "metadata": {},
   "source": [
    "Yes, Lasso Regression can be used for non-linear regression problems. The essential part of Lasso is just adding an L1 norm of the coefficients to the main term. There’s no reason the model has to be linear. It may not have an analytic solution or be convex, but there’s nothing stopping you from trying it out, and it should still induce sparsity, contingent on a large enough lambda."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b0adb4e-7c12-4800-bd42-d3ff3c2e1a82",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41e4f102-8c47-485a-aafc-45c5d481b7c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cf908cd5-13ea-4b30-b3e5-185bba86d3eb",
   "metadata": {},
   "source": [
    "Q6. What is the difference between Ridge Regression and Lasso Regression?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06dc363f-ea25-4aad-ad2d-7ea3924b16c1",
   "metadata": {},
   "source": [
    "Solution :"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cca53635-ff76-47e4-b3eb-dfcaaab592f6",
   "metadata": {},
   "source": [
    "The main difference between Ridge Regression and Lasso Regression is the way they shrink the coefficients. Ridge regression can reduce all the coefficients by a small amount but Lasso can reduce some features more than others and hence can completely eliminate those features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "036b8874-b327-4522-a2a7-156a8a46f309",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f6275e2-2858-45e3-b29d-82f1eb011640",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2d030d0e-46a5-49f1-80ab-55faa3256a1c",
   "metadata": {},
   "source": [
    "Q7. Can Lasso Regression handle multicollinearity in the input features? If yes, how?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8152a818-1fa5-4544-8317-6a666cf61d27",
   "metadata": {},
   "source": [
    "Solution :"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f903ccb-828d-49e9-9519-21752aeedc9d",
   "metadata": {},
   "source": [
    "Yes, Lasso Regression can handle multicollinearity in the input features. Multicollinearity occurs when two or more predictor variables in a multiple regression model are highly correlated. This can lead to unstable estimates of the regression coefficients and make it difficult to interpret the results of the model.\n",
    "\n",
    "Lasso regression can shrink some coefficients to exactly zero.In this way , the variables which are highly correlated are removed.\n",
    "\n",
    "In practice, Lasso regression can be used to analyze any data that suffers from multicollinearity. However, it’s important to note that Lasso regression is not as effective at handling multicollinearity as Ridge regression and other methods like PCR,PLSR.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf4afd02-260d-411d-bedb-16a238909649",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cfbb293-6d0b-48e3-b0fd-6b9bb47c62f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1a29bba9-157b-4cdb-abb8-b64f34433cf6",
   "metadata": {},
   "source": [
    "Q8. How do you choose the optimal value of the regularization parameter (lambda) in Lasso Regression?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9d4bcc2-10d5-4aff-9747-37c052f4e7a7",
   "metadata": {},
   "source": [
    "Solution :"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b90f1bab-9c0a-434d-ae87-2669a8768b93",
   "metadata": {},
   "source": [
    "The optimal value of the regularization parameter (lambda) in Lasso Regression can be chosen by cross-validation. When lambda is small, the result is essentially the least squares estimates. As lambda increases, shrinkage occurs so that variables that are at zero can be thrown away. To determine the optimal value for λ, we can fit several models using different values for λ and choose λ to be the value that produces the lowest test MSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b9daee0-e21c-481e-9791-1129c1aa9974",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
