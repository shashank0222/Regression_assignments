{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a02e9a23-de12-43e6-9354-ecd53951fdaa",
   "metadata": {},
   "source": [
    "Q1: What are missing values in a dataset? Why is it essential to handle missing values? Name some\n",
    "algorithms that are not affected by missing values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e01a329-e13a-4675-b292-766b4af3f432",
   "metadata": {},
   "source": [
    "Solution :"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "510f4227-3d04-4dae-9fc8-c975bad1502c",
   "metadata": {},
   "source": [
    "**Missing values** in a dataset are data that are not stored for certain variables or participants. They can occur due to various reasons, such as incomplete data entry, equipment malfunctions, lost files, etc. Missing values can be classified into three types: Missing Completely at Random (MCAR), Missing at Random (MAR), and Missing Not at Random (MNAR).\n",
    "\n",
    "\n",
    "Handling missing values is crucial because they can lead to a lack of precision in the statistical analysis. If not handled properly, you may end up building a biased machine learning model, leading to incorrect results. It's important to handle missing values to avoid this and to successfully manage data and draw accurate inferences about the data.\n",
    "\n",
    "\n",
    "Some machine learning algorithms can handle missing values. For example, the **k-nearest neighbors (KNN)** algorithm can ignore a column when a value is missing. It works on the principle of a distance measure. Another algorithm that can handle missing values is **Naive Bayes**. These algorithms can support missing values when making a prediction.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f04528e-a9db-4424-b4d1-af016d5fdc15",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e8a6754-fc70-4b12-b328-a9f67683b650",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "368f0f49-55d9-4b8e-8c44-2579b19db9b2",
   "metadata": {},
   "source": [
    "Q2: List down techniques used to handle missing data. Give an example of each with python code."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3503b0f7-1db3-4f02-bf13-a81392f5dc90",
   "metadata": {},
   "source": [
    "Solution :"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "738576f0-9754-49ea-b87d-cb16a7965b05",
   "metadata": {
    "tags": []
   },
   "source": [
    "There are several techniques to handle missing data in a dataset:\n",
    "\n",
    "1. Deleting Rows with Missing Values: This method involves removing the rows that contain missing values. However, it is not generally advised as it might result in loss of information from other columns which do not have missing values.\n",
    "\n",
    "2. Mean/Median/Mode Imputation: This method involves filling the missing values with the mean, median, or mode of the non-missing data in the same column.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fcfda87c-2490-4585-909f-e46c3865b758",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     A    B   C\n",
       "0  1.0  5.0   9\n",
       "3  4.0  8.0  12"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# deleting rows with missing values\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.DataFrame({'A': [1, 2, np.nan, 4], 'B': [5, np.nan, 7, 8], 'C': [9,10,10,12] })\n",
    "\n",
    "# deleting rows with missing values\n",
    "df.dropna()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cf714694-795f-4bf5-9145-d0cb427423f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     A    B   C\n",
       "0  1.0  5.0   9\n",
       "1  2.0  NaN  10\n",
       "2  2.0  7.0  10\n",
       "3  4.0  8.0  12"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filling missing values with mean \n",
    "df['A'] = df['A'].fillna(int(df['A'].mean()))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31942b18-bf77-4a68-9542-11cba2c50a5d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e83038f6-6d76-485e-b2ba-8767a61dd544",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8d92bbbd-857c-4603-9404-02c610057ccf",
   "metadata": {},
   "source": [
    "Q3: Explain the imbalanced data. What will happen if imbalanced data is not handled?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4ca2cee-e359-4084-ad8b-171aaf1a758e",
   "metadata": {},
   "source": [
    "Solution: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e91b434-2767-4ef5-920e-72eeb6846552",
   "metadata": {},
   "source": [
    "**Imbalanced data** refers to a situation in classification machine learning where one target class represents a significant portion of observations. This means that one class has a much higher or lower number of observations than the other class(es). Imbalanced data can pose challenges for machine learning algorithms and affect their performance1. It can occur in various domains such as finance, healthcare, and public sectors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "261d4b1d-e7d9-438b-a982-79449a2327a0",
   "metadata": {},
   "source": [
    "If imbalanced data is not handled properly, it can lead to models that are **biased** toward the majority class, resulting in poor performance of the minority class. This is because many machine learning algorithms are designed to maximize overall accuracy. As a result, the minority class observations might look like noise to the model and are often ignored. This can lead to misleading accuracy scores and poor model performance. Moreover, imbalanced data can cause **overfitting**, where the model learns to memorize the majority class and fails to generalize to new, unseen data. This results in poor performance on real-world applications, as the model cannot adapt to variations in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93cdac90-cce6-47ed-9e40-0e5784368f5f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b0bbc4b-9bcc-4eec-b841-0c49da4a6401",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a2a0953e-0d42-4c1b-bb37-8a7ec2b1866e",
   "metadata": {},
   "source": [
    "Q4: What are Up-sampling and Down-sampling? Explain with an example when up-sampling and down-\n",
    "sampling are required."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06fc5e27-b2e0-47a9-8b6e-ff1c9bad86c5",
   "metadata": {},
   "source": [
    "Solution: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ab18d4a-89e1-42d5-b407-2563fae35ab1",
   "metadata": {},
   "source": [
    "**Up-sampling** is the process of increasing the frequency or size of the data. In the context of image processing, up-sampling increases the resolution and size of the image. It involves adding more data points between the existing data points in the dataset.\n",
    "\n",
    "**Down-sampling**, on the other hand, is the process of decreasing the frequency or size of the data. In image processing, down-sampling reduces the number of pixels in an image, thereby decreasing its resolution and size."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee2e75b5-039a-4bfb-8a34-c1b703e297ed",
   "metadata": {},
   "source": [
    "**Example when up-sampling and down-sampling are required:**\n",
    "\n",
    "In **image processing**, down-sampling can be used to reduce the storage and/or transmission requirements of images. For instance, if you have a high-resolution image that you need to send over a network with bandwidth limitations, you might down-sample the image to reduce its size.\n",
    "\n",
    "Up-sampling, on the other hand, can be used when you want to increase the resolution of an image. For example, if you have a low-resolution image that you want to print in a large format, you might up-sample the image to increase its resolution and avoid pixelation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "775a5c86-5073-4ee7-8c9a-eaca331e08df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75f9c543-ef7e-4fbf-9857-ae6a5f7cef64",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1d28ad3e-14b1-4387-ac0e-b7a91b0e6a61",
   "metadata": {},
   "source": [
    "Q5: What is data Augmentation? Explain SMOTE."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4519ba00-61d8-47ec-94cc-2afabb5e6bd9",
   "metadata": {},
   "source": [
    "Solution:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f86f54d-59f3-479d-9476-771f5a54545a",
   "metadata": {},
   "source": [
    "Data augmentation is a set of techniques used to increase the amount and diversity of data by generating new data points from existing data. This process does not involve collecting new data, but rather transforming the already present data. In the context of image processing, for example, data augmentation might involve operations such as rotation, shearing, zooming, cropping, flipping, and changing the brightness level."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4c62d2e-a165-424f-8699-b0be62cdf720",
   "metadata": {},
   "source": [
    "SMOTE is a technique used in ML to address imbalance datasets where the minority class has significantly fewer instances than the majority class. SMOTE involves generating synthetic instances of the minority class by interpolating between existing instances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8e51054-5a24-4762-88cf-60202d2d11ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2db8a937-32cb-41c8-9d19-5b00d549f929",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b682ea58-3fef-407a-b43a-089714982831",
   "metadata": {},
   "source": [
    "Q6: What are outliers in a dataset? Why is it essential to handle outliers?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3152449d-353d-411c-8ad4-422a2fa5c468",
   "metadata": {},
   "source": [
    "Solution:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f924f1a-e8ad-4457-91df-dea7aad9c096",
   "metadata": {},
   "source": [
    "Outliers in a dataset are data points that deviate significantly from the rest of the observations. They are extreme values that stand out greatly from the overall pattern of values in a dataset or graph. Outliers can occur due to various reasons such as variability in the data, experimental errors, or human errors.\n",
    "\n",
    "Handling outliers is crucial for several reasons:\n",
    "1. Detecting Errors\n",
    "2. Understanding Natural Variation\n",
    "3. Impacting Statistical Measures\n",
    "4. Ensuring Accurate Results\n",
    "5. Affecting Machine Learning Models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54e3fb87-a4c6-42a6-9e19-674320135290",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0d172fc-5dd0-4364-816f-ae16cef8bc38",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a5de9cc3-4b9f-4a63-875c-e97ccc55e0c2",
   "metadata": {},
   "source": [
    "Q7: You are working on a project that requires analyzing customer data. However, you notice that some of\n",
    "the data is missing. What are some techniques you can use to handle the missing data in your analysis?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad12f2b3-9efd-46c6-9cb0-ebd016e3eca1",
   "metadata": {},
   "source": [
    "Solution:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c875c53-d01d-46a1-8a70-13ce0d6f8eb8",
   "metadata": {},
   "source": [
    "There are several techniques to handle missing data in a dataset:\n",
    "1. Deleting Rows with missing values\n",
    "2. Mean/Median/Mode Imputation\n",
    "3. Random Sample Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "832fd6b9-fe4e-42b8-bac8-0c7359e3c0a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a86ca83d-895b-4d88-83e4-c001239ca581",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e5c3ae91-2310-472e-9ca4-f7efbfff9d0c",
   "metadata": {},
   "source": [
    "Q8: You are working with a large dataset and find that a small percentage of the data is missing. What are\n",
    "some strategies you can use to determine if the missing data is missing at random or if there is a pattern\n",
    "to the missing data?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ce89358-2987-4297-a8b9-a8a491df89dc",
   "metadata": {},
   "source": [
    "Solution:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "580fa6ae-d23f-44cb-b312-6eeec9d5161c",
   "metadata": {},
   "source": [
    "There are several strategies to determine if missing data is missing at random or if there is a pattern:\n",
    "\n",
    "1. **Try to obtain the missing data**: If possible, try to collect the missing data. This could involve reaching out to the data source or conducting further research.\n",
    "\n",
    "2. **Leave out incomplete cases and use only those for which all variables are available**: This strategy involves analyzing only the complete cases in your dataset.\n",
    "\n",
    "3. **Replace missing data by a conservative estimate, e.g., the sample mean**: This involves imputing the missing values with a conservative estimate like the mean, median, or mode.\n",
    "\n",
    "4. **Try to estimate the missing data from the other data on the person**: If you have other related variables in your dataset, you can use them to estimate the missing values.\n",
    "\n",
    "5. **Mean or Median Imputation**: This method involves filling the missing values with the mean or median of the non-missing data in the same column.\n",
    "\n",
    "6. **Multivariate Imputation by Chained Equations (MICE)**: This is a more advanced method that involves using multiple variables in your dataset to estimate the missing values.\n",
    "\n",
    "7. **Random Forest**: This method involves using a Random Forest model to predict and fill in missing values based on other variables.\n",
    "\n",
    "Remember that it's important to understand why your data is missing before deciding on a strategy. The reason for the missing data can help you determine whether it's missing at random (MAR), missing completely at random (MCAR), or missing not at random (MNAR).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d6218f-24dd-490a-8e1a-396f24b15e2c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50b4112d-589b-4dd3-bd13-39c5c8d73dd5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8b2c80b4-4fcb-479e-b0aa-6395b752b7ef",
   "metadata": {},
   "source": [
    "Q9: Suppose you are working on a medical diagnosis project and find that the majority of patients in the\n",
    "dataset do not have the condition of interest, while a small percentage do. What are some strategies you\n",
    "can use to evaluate the performance of your machine learning model on this imbalanced dataset?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea1324f5-a408-4b19-b023-132bcefda6ad",
   "metadata": {},
   "source": [
    "Solution: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8c78169-b87b-4e6c-81f8-5ddba520786b",
   "metadata": {},
   "source": [
    "In terms of evaluation metrics, accuracy might not be a good indicator due to the imbalance. Instead, consider using:\n",
    "\n",
    "* Precision: It tells us what proportion of patients that we diagnosed as having the condition, actually had the condition.\n",
    "\n",
    "* Recall (Sensitivity): It tells us what proportion of patients that actually had the condition were diagnosed by the algorithm as having the condition.\n",
    "\n",
    "* F1-Score: It is the harmonic mean of precision and recall and provides a balance between them.\n",
    "\n",
    "* Area Under the Receiver Operating Characteristic Curve (AUROC): It tells us how much the model is capable of distinguishing between classes.\n",
    "\n",
    "* Confusion Matrix: It is a table that describes the performance of a classification model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ca00e68-d495-4f0a-b405-4fb962672e9c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6c26609-a42a-4331-af70-022c5ca13fb7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c1ea19fc-3313-4a67-b73c-d3b4a903c3a5",
   "metadata": {},
   "source": [
    "Q10: When attempting to estimate customer satisfaction for a project, you discover that the dataset is\n",
    "unbalanced, with the bulk of customers reporting being satisfied. What methods can you employ to\n",
    "balance the dataset and down-sample the majority class?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78d37b28-ec70-4dbb-a862-df685bdf8db6",
   "metadata": {},
   "source": [
    "Solution: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0829e77d-7789-49a7-85eb-db27d56e8af2",
   "metadata": {},
   "source": [
    "When dealing with an imbalanced dataset where the majority of customers are satisfied, you can use the following methods to down-sample the majority class and balance the dataset:\n",
    "\n",
    "1. **Random Under-sampling**: This involves randomly eliminating instances from the majority class to achieve a more balanced dataset. However, this method might discard potentially useful data.\n",
    "\n",
    "2. **Cluster-Based Under-sampling**: In this method, the majority class is divided into several clusters. Instances in each cluster are then under-sampled. This ensures that the under-sampling process does not result in loss of data diversity.\n",
    "\n",
    "3. **Tomek Links**: Tomek links are pairs of instances of opposite classes who are their own nearest neighbors. In other words, they are instances that are very close to each other but belong to different classes. You can remove the instances of the majority class from each pair to increase the separation between classes.\n",
    "\n",
    "4. **Edited Nearest Neighbors (ENN)**: This method removes any instance in the majority class whose prediction made by its three nearest neighbors disagrees with its actual class.\n",
    "\n",
    "Remember, while these methods can help balance the classes, they might also remove potentially important information. It's essential to keep this in mind and consider using a combination of under-sampling and over-sampling (for the minority class) techniques for best results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "857e22b5-1cea-446d-8e77-6b03e6c46a1d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "149d52ec-9f9f-469a-93b9-fe3fd3484a0d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ca536cb0-7488-406c-8c0c-70885ea8c876",
   "metadata": {},
   "source": [
    "Q11: You discover that the dataset is unbalanced with a low percentage of occurrences while working on a\n",
    "project that requires you to estimate the occurrence of a rare event. What methods can you employ to\n",
    "balance the dataset and up-sample the minority class?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7115049-368f-4792-af34-f7c728b2609a",
   "metadata": {},
   "source": [
    "Solution: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "157bc4b2-37eb-428a-8dab-aa55d9610d13",
   "metadata": {},
   "source": [
    "When dealing with an imbalanced dataset where the minority class represents a rare event, you can use the following methods to up-sample the minority class and balance the dataset:\n",
    "\n",
    "1. **Random Over-sampling**: This involves randomly duplicating instances from the minority class to achieve a more balanced dataset. However, this method might lead to overfitting due to the exact replication of data points.\n",
    "\n",
    "2. **Synthetic Minority Over-sampling Technique (SMOTE)**: This method creates synthetic instances of the minority class by interpolating between existing ones. This can increase the diversity of data, reducing the risk of overfitting compared to random over-sampling.\n",
    "\n",
    "3. **Adaptive Synthetic (ADASYN) Sampling Method**: This is an improved version of SMOTE. It uses a density distribution as a criterion to automatically decide the number of synthetic samples that need to be generated for each minority sample.\n",
    "\n",
    "4. **Borderline-SMOTE**: This is a variant of SMOTE that selects instances near the decision boundary of the minority class for generating synthetic instances.\n",
    "\n",
    "Remember, while these methods can help balance the classes, they might also introduce noise into the dataset. It's essential to keep this in mind and consider using a combination of under-sampling (for the majority class) and over-sampling techniques for best results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "974ec2d1-c976-46a2-911f-84b26a03fcb2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
