{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c90cb273-07ad-4dbc-b595-e38f28107dad",
   "metadata": {},
   "source": [
    "Q1. What is the purpose of grid search cv in machine learning, and how does it work?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e0a60a5-e527-485e-882c-316e4138d918",
   "metadata": {},
   "source": [
    "Solution :"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e99a2ea-573f-4b67-9250-0267933bbeeb",
   "metadata": {},
   "source": [
    "Grid search CV is a technique used in machine learning to find the best hyperparameters for a model. It is an exhaustive search over a specified parameter space that evaluates the performance of the model for each combination of hyperparameters.\n",
    "\n",
    "Grid search CV works by creating an exhaustive set of hyperparameter combinations and training the model on each combination. It then evaluates the performance of the model using cross-validation and selects the combination of hyperparameters that gives the best performance.\n",
    "\n",
    "Grid search CV is useful because it automates the process of finding the best hyperparameters for a model. It saves time and effort by eliminating the need for manual tuning of hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f301a07b-3e0b-4ef6-a13d-1eeeb6afee88",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9a12cd8-704c-4361-bc2c-1a3cec20e611",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "06d79888-cc6e-43a6-bc92-1572066a03c7",
   "metadata": {},
   "source": [
    "Q2. Describe the difference between grid search cv and randomize search cv, and when might you choose\n",
    "one over the other?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79d7c8d9-118d-4419-807d-b5c6fd692f42",
   "metadata": {},
   "source": [
    "Solution:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a78c0511-c5d0-49a8-ae07-b6133febba47",
   "metadata": {},
   "source": [
    "Grid search CV and random search CV are both techniques used in machine learning to find the best hyperparameters for a model.\n",
    "\n",
    "* Grid search CV is an exhaustive search over a specified parameter space that evaluates the performance of the model for each combination of hyperparameters. Grid search CV works by creating an exhaustive set of hyperparameter combinations and training the model on each combination. It then evaluates the performance of the model using cross-validation and selects the combination of hyperparameters that gives the best performance.\n",
    "\n",
    "* Randomized search CV is a technique that tries random combinations of a range of values for each hyperparameter. It is useful when there are many hyperparameters, so the search space is large. It can be used if you have a prior belief on what the hyperparameters should be.\n",
    "\n",
    "Grid search CV is useful when you have a small number of hyperparameters to tune, while randomized search CV is useful when you have many hyperparameters to tune."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5b2f189-e8d2-46b8-ab8f-a775fbc0c4c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db815d52-4c6c-48ac-b1b8-bd31d085c55f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "895d5452-c4c5-4119-b618-39be38c0f6c2",
   "metadata": {},
   "source": [
    "Q3. What is data leakage, and why is it a problem in machine learning? Provide an example."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2e258f6-0304-4945-ab88-fbba63693912",
   "metadata": {},
   "source": [
    "Solution :"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0537f64e-4ae4-484a-9cc4-e9b212fd2b3a",
   "metadata": {},
   "source": [
    "Data leakage is when information from outside the training dataset is used to create the model. This additional information can allow the model to learn or know something that it otherwise would not know and in turn invalidate the estimated performance of the model being constructed.\n",
    "\n",
    "Examples of data leakage in machine learning include:\n",
    "\n",
    "* Sharing data from the test dataset with the training dataset, causing a machine learning model to perform better than it should.\n",
    "* Input data and the target being related in some trivial way.\n",
    "* Using response variables as the predictor, hence giving conclusions such as 'dog belongs to the family of dogs.'\n",
    "\n",
    "An example of data leakage is when data from the test dataset is shared with the training dataset, causing a machine learning model to perform better than it should because it already knows the data that’s being presented."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e41ee5d7-d5d7-43b3-8e8f-daabed1ac028",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec3d5df2-a9bf-4aab-8c10-f4dce51239b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "807bbdb9-85ff-4889-83fd-9a991706443e",
   "metadata": {},
   "source": [
    "Q4. How can you prevent data leakage when building a machine learning model?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8a9c9a7-d1ac-4112-9367-c9f7cb32ae65",
   "metadata": {},
   "source": [
    "Solution :"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0d0a4c9-aafd-4ccd-a8af-fd9cb7b0951e",
   "metadata": {},
   "source": [
    "To prevent data leakage in machine learning, you should:\n",
    "\n",
    "* Remove correlations and duplicates in the dataset.\n",
    "* Ensure temporal coherence and avoid using future information.\n",
    "* Split the dataset into train, validation, and test sets before any preprocessing.\n",
    "* Perform data preparation within your cross-validation folds.\n",
    "* Hold back a validation dataset for final sanity check of your models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c94a0864-b4c1-497a-986f-66e69a3c041d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dedc3a46-8e81-47ae-8697-87462713ae13",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fb0f180e-0d54-4f94-8dc0-cd4c52c9c9a8",
   "metadata": {},
   "source": [
    "Q5. What is a confusion matrix, and what does it tell you about the performance of a classification model?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a5803cf-3b3b-4be8-819e-caeaddf6e2ff",
   "metadata": {},
   "source": [
    "Solution :"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dfba11f-31dd-4f33-a2bd-85046093ae73",
   "metadata": {},
   "source": [
    "* A confusion matrix is a tabular summary of the number of correct and incorrect predictions made by a classifier. \n",
    "* It is used to measure the performance of a classification model. The matrix compares the actual target values with those predicted by the machine learning model.\n",
    "* It can be used to evaluate the performance of a classification model through the calculation of performance metrics like accuracy, precision, recall, and F1-score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c62b017-6277-49e6-adcc-4aa126de2388",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bae1f9ca-5ac6-4f05-87e9-876f119d36e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bea89ee7-4199-4126-b719-580b2be88da6",
   "metadata": {},
   "source": [
    "Q6. Explain the difference between precision and recall in the context of a confusion matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbfe1981-2de7-45ba-8547-e4cb2f987e30",
   "metadata": {},
   "source": [
    "Solution :"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2ef0fbc-83d5-49ee-a126-3f62ef35d885",
   "metadata": {},
   "source": [
    "In the context of a confusion matrix, precision is the ratio of true positives to the sum of true positives and false positives. It measures how many of the positive predictions made by the model are actually correct. Recall is the ratio of true positives to the sum of true positives and false negatives. It measures how many of the actual positive cases were correctly identified by the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6142c37c-4358-49e6-a69e-781ed20bb3cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77ebddab-d0cf-4e4e-8da3-311ba8560da7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ad7a4ff7-5ca5-4724-bf3d-d0140eefb316",
   "metadata": {},
   "source": [
    "Q7. How can you interpret a confusion matrix to determine which types of errors your model is making?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "449eb673-1bed-455c-9192-f08ebf53375c",
   "metadata": {},
   "source": [
    "Solution :"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51856289-eb8a-4df0-a63d-2a928eec1359",
   "metadata": {},
   "source": [
    "A confusion matrix can help you determine which types of errors your model is making. The matrix compares the actual target values with those predicted by the machine learning model. It can be used to evaluate the performance of a classification model through the calculation of performance metrics like accuracy, precision, recall, and F1-score.\n",
    "\n",
    "The confusion matrix is a table that summarizes the performance of a classification algorithm. It shows the number of correct and incorrect predictions made by the classifier compared to the actual outcomes. The rows represent the actual class labels, while the columns represent the predicted class labels. The diagonal elements represent the number of correct predictions, while off-diagonal elements represent incorrect predictions. By analyzing these numbers, you can determine which types of errors your model is making."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6186fc84-9816-4d2f-8d28-c36f060a0b3f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8874f4b8-0a94-483a-b8c0-fad398266953",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e82d9401-cdec-4857-9856-efc0f8ca83d4",
   "metadata": {},
   "source": [
    "Q8. What are some common metrics that can be derived from a confusion matrix, and how are they\n",
    "calculated?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00331c4d-875b-4afe-8d15-e15e5b826e47",
   "metadata": {},
   "source": [
    "Solution :"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84692b82-6f8b-43c3-9a30-27d14893ca5b",
   "metadata": {},
   "source": [
    "The following performance metrics can be calculated from a confusion matrix:\n",
    "\n",
    "* Accuracy: The number of samples correctly classified out of all the samples present in the test set.\n",
    "* Precision: The number of true positives divided by the sum of true positives and false positives.\n",
    "* Recall: The number of true positives divided by the sum of true positives and false negatives.\n",
    "* F1-score: The harmonic mean of precision and recall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c7a34f0-f912-4b79-9696-6bc0fe31a051",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be58720c-f3c4-4347-bdad-d6ed6a6e397a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d9d1eca0-c9e5-4cd3-8e2c-a651d6bcf416",
   "metadata": {},
   "source": [
    "Q9. What is the relationship between the accuracy of a model and the values in its confusion matrix?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04a2d01e-1bce-4248-ac3c-33a2b975656b",
   "metadata": {},
   "source": [
    "Solution :"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "059026a7-165c-492f-ac38-aca7b26d67b1",
   "metadata": {},
   "source": [
    "The accuracy of a model can be calculated using a confusion matrix. The accuracy is calculated using the formula:\n",
    "\n",
    "Accuracy = (TN + TP) / (TN + FP + FN + TP)\n",
    "\n",
    "The confusion matrix gives information about the model’s performance, and the diagonal elements are the correctly predicted samples. The overall accuracy can be calculated by dividing the number of correctly predicted samples by the total number of samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec30da89-0851-44c4-be08-f4133d00fed0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81ece804-2785-4700-b363-4fe1b89817cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1c7d578e-5c94-431d-b4ad-b4bbce5b3372",
   "metadata": {},
   "source": [
    "Q10. How can you use a confusion matrix to identify potential biases or limitations in your machine learning\n",
    "model?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f094a54-07de-4f84-8fda-79f2c83b7d6a",
   "metadata": {},
   "source": [
    "Solution "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b457242-5bc2-43ff-888a-00422f10e5a3",
   "metadata": {},
   "source": [
    "A confusion matrix can help you identify potential biases or limitations in your machine learning model. By analyzing the matrix, you can determine which types of errors your model is making. This can help you identify areas where your model may be biased or where it may be limited in its ability to make accurate predictions.\n",
    "\n",
    "For example, if your model is making more false positives than false negatives, it may be biased towards predicting positive outcomes. If your model is making more false negatives than false positives, it may be biased towards predicting negative outcomes. By identifying these biases, you can adjust your model to improve its performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aafddee5-71dc-4ebe-bbab-91e604e786fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd5986da-4624-48b0-8c96-8b693e6738f2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
